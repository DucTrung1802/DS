{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orange brix Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import pickle\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Các cài đặt khác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biến GENERATE_PLOTS dùng để bật tắt việc vẽ đồ thị.\n",
    "# Tắt đi để tăng tốc chạy test. (không chạy những hàm plot)\n",
    "GENERATE_PLOTS: bool = False\n",
    "\n",
    "# Biến boolean để bật tắt việc traing model khi ấn \"Run all\"\n",
    "TRAIN_MODEL_1: bool = False\n",
    "TRAIN_MODEL_2: bool = False\n",
    "TRAIN_MODEL_3: bool = False\n",
    "TRAIN_MODEL_4: bool = False\n",
    "TRAIN_MODEL_5: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tạo các Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Utilities có các phương thức tiện ích.\n",
    "# Các class khác muốn sử dụng các tiện ích này thì\n",
    "# chỉ cần kế thừa class Utilities này.\n",
    "\n",
    "class Utilities:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_categorical_numeric_cols(self, dataframe: pd.DataFrame):\n",
    "        if len(dataframe) == 0:\n",
    "            raise Exception(\"No records found!\")\n",
    "\n",
    "        numeric_cols = []\n",
    "        categorical_cols = []\n",
    "\n",
    "        for col in dataframe.columns:\n",
    "            if isinstance(dataframe[col][0], bool) or not isinstance(\n",
    "                dataframe[col][0], (int, float, np.int8, np.int16, np.int32, np.int64, np.float16, np.float32, np.float64)\n",
    "            ):\n",
    "                categorical_cols.append(col)\n",
    "            else:\n",
    "                numeric_cols.append(col)\n",
    "\n",
    "        return (categorical_cols, numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enum ScalerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khai báo Enum của các loại Scaler data từ submoule\n",
    "# preprocessing của thư viện sklearn.\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    MaxAbsScaler,\n",
    "    MinMaxScaler,\n",
    "    Normalizer,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")\n",
    "\n",
    "\n",
    "class ScalerType(Enum):\n",
    "    Raw_ = None\n",
    "    MaxAbsScaler_ = MaxAbsScaler\n",
    "    MinMaxScaler_ = MinMaxScaler\n",
    "    Normalizer_ = Normalizer\n",
    "    RobustScaler_ = RobustScaler\n",
    "    StandardScaler_ = StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Dataset chứa 1 dataframe và các metadata của\n",
    "# dataframe này (tên, loại scaler, tên cột biến định\n",
    "# danh, tên cột biến định lượng)\n",
    "\n",
    "\n",
    "class Dataset(Utilities):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        dataframe: pd.DataFrame,\n",
    "        scaler_type: ScalerType = ScalerType.Raw_,\n",
    "    ):\n",
    "        self.name: str = name\n",
    "        self.dataframe: pd.DataFrame = dataframe\n",
    "        self.categorical_cols: list[str] = []\n",
    "        self.numeric_cols: list[str] = []\n",
    "        self.scaler_type: ScalerType = scaler_type\n",
    "\n",
    "        self.categorical_cols, self.numeric_cols = self.get_categorical_numeric_cols(\n",
    "            self.dataframe\n",
    "        )\n",
    "\n",
    "    def get_name(self) -> str:\n",
    "        return self.name\n",
    "\n",
    "    def get_dataframe(self) -> pd.DataFrame:\n",
    "        return self.dataframe\n",
    "\n",
    "    def detect_categorical_numeric_cols(self):\n",
    "        if len(self.dataframe) == 0:\n",
    "            raise Exception(\"No records found!\")\n",
    "\n",
    "        self.numeric_cols = []\n",
    "        self.categorical_cols = []\n",
    "\n",
    "        for col in self.dataframe.columns:\n",
    "            try:\n",
    "                float(self.dataframe[col][0])\n",
    "                self.numeric_cols.append(col)\n",
    "            except:\n",
    "                self.categorical_cols.append(col)\n",
    "\n",
    "    def get_numeric_cols(self) -> list[str]:\n",
    "        return self.numeric_cols\n",
    "\n",
    "    def get_numeric_dataframe(self) -> pd.DataFrame:\n",
    "        return self.dataframe[self.numeric_cols]\n",
    "\n",
    "    def get_categorical_dataframe(self) -> pd.DataFrame:\n",
    "        return self.dataframe[self.categorical_cols]\n",
    "\n",
    "    def get_scaler_type(self) -> ScalerType:\n",
    "        return self.scaler_type\n",
    "\n",
    "    def concat_dataframe(self, additional_dataframe: pd.DataFrame):\n",
    "        if len(additional_dataframe) == len(self.dataframe):\n",
    "            self.dataframe = pd.concat([self.dataframe, additional_dataframe], axis=1)\n",
    "            self.detect_categorical_numeric_cols()\n",
    "\n",
    "    def get_one_hot_vectorized_dataset(\n",
    "        self, categorical_col: str, print_name: bool = True\n",
    "    ):\n",
    "        if categorical_col in self.categorical_cols:\n",
    "            dummies_dataframe = pd.get_dummies(self.dataframe[categorical_col])\n",
    "            dummies_dataframe = pd.concat([dummies_dataframe, self.dataframe], axis=1)\n",
    "            new_dataset_name = self.name + \"_ohv_\" + categorical_col\n",
    "            if print_name:\n",
    "                print(new_dataset_name)\n",
    "            return Dataset(\n",
    "                name=new_dataset_name,\n",
    "                dataframe=dummies_dataframe,\n",
    "                scaler_type=self.scaler_type,\n",
    "            )\n",
    "        elif categorical_col in self.numeric_cols:\n",
    "            print(\"Records for input column name are not categorical!\")\n",
    "        else:\n",
    "            print(\"Input column name does not exists!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enum ModelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelType là Enum khai báo các loại model từ thư viện\n",
    "# sklearn và một số mô hình từ nguồn khác (xgb, lightgbm).\n",
    "# Mỗi loại model được khai báo một bộ tham số đi kèm.\n",
    "\n",
    "\n",
    "class ModelType(Enum):\n",
    "    LINEAR_REGRESSION: dict = {}\n",
    "    SVR: dict = {\n",
    "        \"kernel\": \"rbf\",  # | linear, poly, rbf\n",
    "        \"degree\": 3,\n",
    "        \"gamma\": \"scale\",\n",
    "        \"coef0\": 0,\n",
    "        \"tol\": 1e-3,\n",
    "        \"C\": 1.0,  # 0.1 - 2 step 0.1\n",
    "        \"epsilon\": 0.1,\n",
    "    }\n",
    "    DECISION_TREE: dict = {\n",
    "        \"criterion\": \"squared_error\",\n",
    "        \"splitter\": \"best\",\n",
    "        \"max_depth\": None,  # 1 - number of feature\n",
    "        \"min_samples_split\": 2,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"min_weight_fraction_leaf\": 0.0,\n",
    "        \"max_features\": None,  # int 2->5 {“sqrt”, “log2”}, default=None\n",
    "        \"random_state\": 42,\n",
    "        \"max_leaf_nodes\": None,\n",
    "        \"min_impurity_decrease\": 0,\n",
    "    }\n",
    "    RANDOM_FOREST: dict = {\n",
    "        \"n_estimators\": 100,  # int 100-1000 (step 100)\n",
    "        \"criterion\": \"squared_error\",\n",
    "        \"max_depth\": None,  # 1 - number of feature\n",
    "        \"min_samples_split\": 2,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"min_weight_fraction_leaf\": 0.0,\n",
    "        \"max_features\": 1.0,  # int 2->5 {“sqrt”, “log2”}, default=None\n",
    "        \"max_leaf_nodes\": None,\n",
    "        \"min_impurity_decrease\": 0.0,\n",
    "    }\n",
    "    LIGHT_GBM: dict = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_leaves\": 31,\n",
    "        \"max_depth\": -1,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"n_estimator\": 100,  # int 100-1000 (step 100)\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "    XGB: dict = {\n",
    "        \"objective\": \"reg:linear\",\n",
    "        \"n_estimators\": 10,  # int 100-1000 (step 100)\n",
    "        \"seed\": 123,\n",
    "        \"verbosity\": 0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Result dùng để chứa kết quả huấn luyện và các\n",
    "# thông tin liên quan của một bộ (mô hình + dữ liệu).\n",
    "\n",
    "# Một kết quả gồm:\n",
    "# - Tên bộ dữ liệu\n",
    "# - Tên của bộ tham số pretrained\n",
    "# - Loại mô hình\n",
    "# - Loại scaler\n",
    "# - Kết quả r^2\n",
    "# - Kết quả mse\n",
    "# - Các tham số pretrained\n",
    "\n",
    "\n",
    "class Result:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_name: str,\n",
    "        pretrained_model_features: str,\n",
    "        model_type: ModelType,\n",
    "        scaler_type: str,\n",
    "        r2: float,\n",
    "        mse: float,\n",
    "        params: str,\n",
    "    ):\n",
    "        self.result = [\n",
    "            dataset_name,\n",
    "            pretrained_model_features,\n",
    "            model_type,\n",
    "            scaler_type,\n",
    "            r2,\n",
    "            mse,\n",
    "            params,\n",
    "        ]\n",
    "\n",
    "    def get_result(self):\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class ResultFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class ResultFrame chứa bảng chứa tất cả kết quả của\n",
    "# một vòng huấn luyện mô hình.\n",
    "# ResultFrame chứa một pd.DataFrame nên có thể hỗ trợ\n",
    "# việc sắp xếp, lọc, xuất kết quả...\n",
    "\n",
    "\n",
    "class ResultFrame:\n",
    "    def __init__(self):\n",
    "        self.result_frame: pd.DataFrame = pd.DataFrame()\n",
    "        self.count = 0\n",
    "\n",
    "        self.start_up()\n",
    "\n",
    "    def start_up(self):\n",
    "        self.result_frame[\"dataset_name\"] = []\n",
    "        self.result_frame[\"pretrained_model_features\"] = []\n",
    "        self.result_frame[\"model_type\"] = []\n",
    "        self.result_frame[\"scaler_type\"] = []\n",
    "        self.result_frame[\"r2\"] = []\n",
    "        self.result_frame[\"mse\"] = []\n",
    "        self.result_frame[\"params\"] = []\n",
    "\n",
    "    def add_result(self, new_result: Result):\n",
    "        self.result_frame.loc[self.count] = new_result.result\n",
    "        self.count += 1\n",
    "\n",
    "    def display_result(self, display_rows: int = 30):\n",
    "        self.result_frame.sort_values([\"r2\", \"mse\"], ascending=False, inplace=True)\n",
    "        if display_rows < 0:\n",
    "            display_rows = 30\n",
    "        display(self.result_frame.head(display_rows))\n",
    "\n",
    "    def save_result(self, filename=None, overwrite=False):\n",
    "        if self.result_frame.shape[0] == 0:\n",
    "            print(\"Result has no records!\")\n",
    "        elif not filename:\n",
    "            filename = (\n",
    "                self.result_frame[\"dataset_name\"][0]\n",
    "                + \"_\"\n",
    "                + self.result_frame[\"pretrained_model_features\"][0]\n",
    "                + \".xlsx\"\n",
    "            )\n",
    "            self.result_frame.to_excel(filename)\n",
    "        else:\n",
    "            file_exists = os.path.isfile(os.path.join(os.getcwd(), filename))\n",
    "            if file_exists and not overwrite:\n",
    "                print(\"Error: CANNOT SAVE FILE.\")\n",
    "                print(\"A file with the same name already exists.\")\n",
    "                print(\n",
    "                    \"Set overwrite to True to overwrite existed file or change file name!\"\n",
    "                )\n",
    "            else:\n",
    "                self.result_frame.to_excel(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Model (là class quan trọng nhất trong notebook này)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Model dùng để tiền xử lý dữ liệu, huấn luyện và\n",
    "# đánh giá mô hình với bộ dữ liệu đã cho ở đầu vào.\n",
    "\n",
    "# Tham số đầu vào:\n",
    "# - dataset_name: tên của Dataset\n",
    "# - pretrained_model_features: tên của bộ tham số pretrained\n",
    "# - model_type: loại Model\n",
    "# - x_cols: một list chứa tên các cột sử dụng làm biến giải thích\n",
    "# - y_cols: một list chứa tên các cột biến phản hồi\n",
    "# - dataset: dataset mình muốn xử lý (dataset này có thể có\n",
    "#       các cột không liên quan, các dữ liệu cho X và Y sẽ được\n",
    "#       trích xuất tự động và các dữ liệu không liên quan sẽ bị loại bỏ)\n",
    "# - scaler_type: loại scaler cho dữ liệu\n",
    "\n",
    "\n",
    "class Model(Utilities):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_name: str,\n",
    "        pretrained_model_features: list[str],\n",
    "        model_type: ModelType,\n",
    "        x_cols: list[str],\n",
    "        y_cols: list[str],\n",
    "        dataset: Dataset,\n",
    "        scaler_type: ScalerType = ScalerType.Raw_,\n",
    "    ):\n",
    "\n",
    "        if len(x_cols) == 0 or len(y_cols) == 0:\n",
    "            raise Exception(\"Data columns are not specified!\")\n",
    "\n",
    "        self.dataset_name: str = dataset_name\n",
    "        self.model_type: ModelType = model_type\n",
    "        self.pretrained_model_features = str(pretrained_model_features)\n",
    "        self.scaler_type: ScalerType = scaler_type\n",
    "        self.scaler = self.get_scaler(self.scaler_type)  # could be None\n",
    "        self.params = self.model_type.value\n",
    "        self.x_dataset: Dataset = None\n",
    "        self.y_dataset: Dataset = None\n",
    "        self.inner_model = None\n",
    "        self.r2 = None\n",
    "        self.mse = None\n",
    "\n",
    "        self.preprocess_data(x_cols, y_cols, dataset)\n",
    "\n",
    "    # Extract data from x_cols and y_cols\n",
    "    # Redetect categorical and numeric columns\n",
    "    def preprocess_data(self, x_cols: list[str], y_cols: list[str], dataset: Dataset):\n",
    "        x_dataset_new_name = dataset.get_name() + \"_x\"\n",
    "        y_dataset_new_name = dataset.get_name() + \"_y\"\n",
    "        scaler_type = dataset.get_scaler_type()\n",
    "        self.x_dataset = Dataset(\n",
    "            name=x_dataset_new_name,\n",
    "            dataframe=dataset.get_dataframe()[x_cols],\n",
    "            scaler_type=scaler_type,\n",
    "        )\n",
    "        self.y_dataset = Dataset(\n",
    "            name=y_dataset_new_name,\n",
    "            dataframe=dataset.get_dataframe()[y_cols],\n",
    "            scaler_type=scaler_type,\n",
    "        )\n",
    "\n",
    "        self.process_x_dataset()\n",
    "\n",
    "    # arrange [numeric_cols, categorical_cols]\n",
    "    def process_x_dataset(self):\n",
    "        new_name = self.x_dataset.get_name()\n",
    "        numeric_dataframe = self.x_dataset.get_numeric_dataframe()\n",
    "        categorical_dataframe = self.x_dataset.get_categorical_dataframe()\n",
    "        scaler_type = self.x_dataset.get_scaler_type()\n",
    "        self.x_dataset = Dataset(\n",
    "            name=new_name,\n",
    "            dataframe=pd.concat([numeric_dataframe, categorical_dataframe], axis=1),\n",
    "            scaler_type=scaler_type,\n",
    "        )\n",
    "\n",
    "    def get_x_list_index_numeric_cols(self):\n",
    "        return list(range(len(self.x_dataset.get_numeric_cols())))\n",
    "\n",
    "    def fit_scaler_and_scale_dataframe(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.scaler is not None:\n",
    "            list_index = self.get_x_list_index_numeric_cols()\n",
    "            X_numeric = X[:, list_index]\n",
    "            X_categorical = X[:, len(list_index) :].astype(int)\n",
    "            self.scaler.fit(X_numeric)\n",
    "            transformed_X = self.scaler.transform(X_numeric)\n",
    "            transformed_X = np.concatenate([transformed_X, X_categorical], axis=1)\n",
    "        else:\n",
    "            transformed_X = X\n",
    "\n",
    "        return transformed_X\n",
    "\n",
    "    def get_x_dataframe(self):\n",
    "        return self.x_dataset.get_dataframe()\n",
    "\n",
    "    def get_y_dataframe(self):\n",
    "        return self.y_dataset.get_dataframe()\n",
    "\n",
    "    def get_scaler(self, scaler_type: ScalerType):\n",
    "        if scaler_type != ScalerType.Raw_:\n",
    "            return scaler_type.value()\n",
    "\n",
    "    def display_progress(self):\n",
    "        print(\n",
    "            f\"Training | ModelType: {self.model_type} | Datasetname: {self.dataset_name} | ScalerType: {self.scaler_type} | Params: {self.params}\"\n",
    "        )\n",
    "        print(f\"R2: {self.r2} | MSE: {self.mse}\")\n",
    "\n",
    "    def fit(self, X=None, Y=None):\n",
    "        if X is None:\n",
    "            X = np.array(self.x_dataset.get_dataframe())\n",
    "            Y = np.array(self.y_dataset.get_dataframe())\n",
    "\n",
    "        model_family = self.model_type.__str__().split(\".\")[-1]\n",
    "\n",
    "        Y = np.squeeze(Y)\n",
    "\n",
    "        # need to scale\n",
    "        transformed_X = self.fit_scaler_and_scale_dataframe(X)\n",
    "\n",
    "        if model_family == \"SVR\":\n",
    "            self.model = SVR(**(self.params)).fit(transformed_X, Y)\n",
    "        elif model_family == \"LINEAR_REGRESSION\":\n",
    "            self.model = LinearRegression(**(self.params)).fit(transformed_X, Y)\n",
    "        elif model_family == \"DECISION_TREE\":\n",
    "            self.model = DecisionTreeRegressor(**(self.params)).fit(transformed_X, Y)\n",
    "        elif model_family == \"RANDOM_FOREST\":\n",
    "            self.model = RandomForestRegressor(**(self.params)).fit(transformed_X, Y)\n",
    "        elif model_family == \"LIGHT_GBM\":\n",
    "            self.model = LGBMRegressor(**(self.params)).fit(transformed_X, Y)\n",
    "        elif model_family == \"XGB\":\n",
    "            self.model = XGBRegressor(**(self.params)).fit(transformed_X, Y)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown model family!\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.scaler is not None:\n",
    "            list_index = self.get_x_list_index_numeric_cols()\n",
    "            X_numeric = X[:, list_index]\n",
    "            X_categorical = X[:, len(list_index) :].astype(int)\n",
    "            transformed_X = self.scaler.transform(X_numeric)\n",
    "            transformed_X = np.concatenate([transformed_X, X_categorical], axis=1)\n",
    "        else:\n",
    "            transformed_X = X\n",
    "        return self.model.predict(transformed_X)\n",
    "\n",
    "    def evaluate(self, X=None, Y=None, method=\"LOOCV\"):\n",
    "        if X is None:\n",
    "            X = np.array(self.x_dataset.get_dataframe())\n",
    "            Y = np.array(self.y_dataset.get_dataframe())\n",
    "        if method == \"LOOCV\":\n",
    "            preds = [0] * len(Y)\n",
    "            total = len(Y)\n",
    "            kf = KFold(n_splits=total)\n",
    "            kf.get_n_splits(Y)\n",
    "\n",
    "        with tqdm(total=total) as pbar:\n",
    "            for i, (train_index, valid_index) in enumerate(kf.split(X, Y)):\n",
    "                X_train = X[train_index]\n",
    "                Y_train = Y[train_index]\n",
    "                X_valid = X[valid_index]\n",
    "                Y_valid = Y[valid_index]\n",
    "\n",
    "                self.fit(X_train, Y_train)\n",
    "\n",
    "                Y_valid_pred = self.predict(X_valid)\n",
    "                for j in range(len(valid_index)):\n",
    "                    index = valid_index[j]\n",
    "                    value = Y_valid_pred[j]\n",
    "                    preds[index] = value\n",
    "                pbar.update(1)\n",
    "\n",
    "        self.r2 = r2_score(Y, preds)\n",
    "        self.mse = mean_squared_error(Y, preds)\n",
    "\n",
    "        self.display_progress()\n",
    "\n",
    "        # Compile result\n",
    "        return Result(\n",
    "            dataset_name=self.dataset_name,\n",
    "            pretrained_model_features=self.pretrained_model_features,\n",
    "            model_type=self.model_type.name,\n",
    "            scaler_type=self.scaler_type.name,\n",
    "            r2=self.r2,\n",
    "            mse=self.mse,\n",
    "            params=self.params,\n",
    "        )\n",
    "\n",
    "    def save(self, filename: str):\n",
    "        pickle.dump(self.inner_model, open(filename, \"wb\"))\n",
    "\n",
    "    def load(self, filename: str):\n",
    "        pickle.dump(self.inner_model, open(filename, \"wb\"))\n",
    "\n",
    "    def set_params(self, params: dict):\n",
    "        self.params = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các biến global trong notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
