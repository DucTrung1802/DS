# -*- coding: utf-8 -*-
"""Stable_Difffusion_inpainting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AfJ0Pw21PaKg33tdgxQ1Tuq1HNO1cvPq
"""

# !pip install diffusers transformers accelerate scipy safetensors
# !pip install carvekit

# from google.colab import drive
# drive.mount("/content/drive")

# https://stable-diffusion-art.com/change-background/

# !unrar x "/content/drive/MyDrive/Colab Notebooks/Hoc_nhom_KHDL/Big_homework/big_homework_data.rar"

from diffusers.utils import make_image_grid, load_image
import matplotlib.pyplot as plt


import PIL.Image

from carvekit.api.interface import Interface
from carvekit.ml.wrap.fba_matting import FBAMatting
from carvekit.ml.wrap.tracer_b7 import TracerUniversalB7
from carvekit.pipelines.postprocessing import MattingMethod
from carvekit.pipelines.preprocessing import PreprocessingStub
from carvekit.trimap.generator import TrimapGenerator


# Check doc strings for more information
seg_net = TracerUniversalB7(device="cpu", batch_size=1)

fba = FBAMatting(device="cpu", input_tensor_size=2048, batch_size=1)
trimap = TrimapGenerator()
preprocessing = PreprocessingStub()
postprocessing = MattingMethod(
    matting_module=fba, trimap_generator=trimap, device="cpu"
)

interface = Interface(
    pre_pipe=preprocessing, post_pipe=postprocessing, seg_pipe=seg_net
)

import cv2
import numpy as np


def get_mask(image):
    bg = interface([image])[0]
    bg = np.array(bg)
    mask_image = PIL.Image.fromarray(cv2.bitwise_not(bg[:, :, 3]))
    return mask_image


from diffusers import StableDiffusionInpaintPipeline
import torch

model_id = "stabilityai/stable-diffusion-2-1"
# model_id = "runwayml/stable-diffusion-inpainting"
pipe = StableDiffusionInpaintPipeline.from_pretrained(
    model_id,
    revision="fp16",
    torch_dtype=torch.float16,
)


# GPU
pipe = pipe.to("cuda")


# image and mask_image should be PIL images.
# The mask structure is white for inpainting and black for keeping as is


def generate_batch(prompt, image, mask_image, num=10):
    final_images = []
    for i in range(1):
        final_image = pipe(prompt=prompt, image=image, mask_image=mask_image).images[0]
        final_images.append(final_image.resize(image.size))
    return final_images


import os


def save_results(final_images, save_path):
    os.makedirs(save_path, exist_ok=True)
    for i in range(len(final_images)):
        final_images[i].save(f"{save_path}/result_{i}.png", "PNG")


uri = "./images/sample.webp"
image = load_image(uri)
plt.imshow(image)
plt.show()
mask_image = get_mask(image)
mask_image

import matplotlib.pyplot as plt

save_dir = "./images/"

prompt = "Add background around this shampoo bottle, with table, tropical beach, an air of freshness and relaxation"
negative_prompt = "make the shampoo bottle rectangular"
images = [image] * 10
prompts = [prompt] * 10
mask_images = [mask_image] * 10
final_image = pipe(prompt=prompts, image=images, mask_image=mask_images).images

for i in range(len(final_image)):
    plt.imshow(final_image[i])
    plt.show()


save_path = f"{save_dir}/output.jpg"
save_results(final_image, save_path)

# pipe.save_pretrained(f"{save_dir}/stable-diffusion-2-1")
